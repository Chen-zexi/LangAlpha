# LangAlpha

 **Note**: Stocksflags is now renamed to LangAlpha
 
LangAlpha is a multi-agent AI equity analysis tool designed to provide comprehensive insights into the stock market. It leverages Large Language Models (LLMs) and agentic workflows to automate data gathering, processing, and analysis, ultimately generating investment signals and supporting user queries through a chatbot interface.

## Example Analysis

Here are some examples of stock analyses generated by LangAlpha:
- [NVIDIA Year-to-Date Analysis](/assets/nvidia_ytd.md)
- [NVIDIA Two-Month Analysis](/assets/nvidia_two_month.md)
- [Tarrif and Trade War Analysis](/assets/tarrif_and_trade_war.md)
- [Market Summary April 23](/assets/market_summary_april_23.md)
- [Nvidia Report](/assets/nvdia_report.md)
- [Tesla Report](/assets/tesla_report.md)
- [Chinese EV Company Report](/assets/chinese_ev_company_report.md)


Depends on the query, it take 2-6 minutes to generate the response. Token usage is generally around 30000+ to 100000+ tokens. Maxium token usage observed is 490000+ tokens.

[Notebook used to generate the analysis](/notebooks/langraph_pipeline_demo.ipynb)


## Key Technologies

*   **Programming Language:** Python
*   **AI/LLM Frameworks:** LangChain, LangGraph
*   **Data Sources:** Multiple APIs (e.g., Polygon, Yahoo Finance, Tickertick, Tavily), Custom MCP Integration, WRDS (Wharton Research Data Services)
*   **Database:** MySQL

## Core Functionality

The project aims to deliver functionality across three core components:

1.  **LLM Agent-Driven Analysis Tool:**
    *   Acts as the primary user interface for research and analysis.
    *   Accepts user queries in natural language.
    *   Utilizes LLM agents to autonomously:
        *   Determine the required information.
        *   Select and execute appropriate data retrieval tools (fetching market data, news, fundamentals from APIs like Polygon, Yahoo Finance, WRDS, and the internal database).
        *   Process the retrieved information using defined analysis tools (e.g., summarization, sentiment analysis, event extraction).
        *   Synthesize findings to answer the user's query.
    *   Integrates with the other components (Trading Signals and Valuation Model) as callable tools within its workflow.

2.  **LLM Agent-Driven Trading Signal Generation:**
    *   Employs specialized LLM agents (`src/agent`) to generate investment/trading signals.
    *   Agents analyze data based on various strategies:
        *   Fundamental analysis.
        *   Macroeconomic assessment.
        *   Technical analysis.
        *   News sentiment interpretation.
    *   Can be executed directly or invoked as a tool by the main Analysis Tool.

3.  **Damodaran Valuation Model:**
    *   Implements valuation methodologies inspired by Professor Aswath Damodaran.
    *   Provides a user interface (details TBD) for manual input and valuation generation.
    *   Offers a callable tool interface, allowing the LLM Agent-Driven Analysis Tool to programmatically generate valuations as part of its research process.

Below is an image demonstrate the current agent workflow
![graph](/assets/graph.png)

## Repository Structure
```
LangAlpha/
├── data                                  # Data directory
├── models                                # Valuation Model directory
├── notebooks/                            # Jupyter notebooks for demonstration
|    ├── checkpoint/
|    |    ├── milestone_3.ipynb             # Checkpoint for milestone 3
|    |    └── milestone_4.ipynb             # Checkpoint for milestone 4
|    ├── demo/                              # Notebook for demo and testing                         
|    └── db_management.ipynb                # Database management tool                 
├── src/                                    # Source code
|    ├── agent/                           # Agent directory
|    |    └── market_intelligence_agent/    # Market Intelligence Agent
|    |         ├── agents/                  # Agent implementations
|    |         ├── prompts/                 # Agent prompts
|    |         ├── tools/                   # Agent tools
|    |         ├── config/                  # Configuration files
|    |         ├── graph/                   # Agent workflow graphs
|    |         ├── service/                 # Service implementations
|    |         ├── crawler/                 # Web crawlers
|    |         └── __init__.py              # Package initialization
|    ├── data_tool/                      # Tools for data retriving
|    |    ├── data_providers/             
|    |    |    ├── connect_wrds.py          # code to connect wrds
|    |    |    ├── financial_datasets.py    # code to retrieve data from financial datasets
|    |    |    ├── polygon.py               # code to retrieve data from polygon
|    |    |    └── yahoo_finance.py         # code to retrieve data from yahoo finance
|    |    ├── data_models.py                # pydantic models
|    |    └── get_data.py                   # get data
|    ├── database_tool/                  # Tools for Database Manipulation   
|    |    ├── connect_db.py                 # connect to database
|    |    ├── create_table.py               # create tables
|    |    └── db_operation.py               # complax data retrieval from database
|    └── llm/                            # LLM config for LLM use oustide of Langraph workflow
|         ├── llm_models.py                 # LLM models
|         └── api_call.py                   # Make api call to LLM
|  
└── ...
```

## Getting Started

### 1. Clone the Repository
```bash
# Clone the repository to your local machine
git clone https://github.com/Chen-zexi/LangAlpha.git

# Navigate to the project directory
cd LangAlpha
```

### 2. Environment Setup
```bash
# Create environment from the environment.yml file
conda env create -f environment.yml

# Activate the environment
conda activate langalpha
```

### 3. Set up API Keys
Set up API keys
Paste the API Keys into .env.example
Remove the .example extension

## Common Git Commands

### Basic Git Workflow
```bash
# Check status of your working directory
git status

# Add files to staging area
git add filename.py            # Add specific file
git add .                      # Add all modified files

# Commit changes with a message
git commit -m "Your descriptive commit message here"

# Push commits to remote repository
git push origin master           # Push to main branch
git push origin your-branch    # Push to a specific branch

# Pull latest changes from remote repository
git pull origin master           # Pull from main branch

# Create and switch to a new branch
git checkout -b new-branch-name

# Switch between branches
git checkout branch-name
```

### Other Useful Git Commands
```bash
# View commit history
git log

# Discard changes in working directory
git checkout -- filename.py

# Fetch updates from remote without merging
git fetch

# Merge a branch into your current branch
git merge branch-name

# View differences between working directory and last commit
git diff
```

## Team Members: 
- Alan zc2610@nyu.edu
- Jackson jc13246@nyu.edu
- Tyler tan4742@nyu.edu
- April asl8466@nyu.edu
- Vinci cc9100@nyu.edu