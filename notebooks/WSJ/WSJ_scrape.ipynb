{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.wsj.com/\"\n",
    "ARG_WINDOW_SIZE = \"--window-size=1920,1080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    def __init__(self):\n",
    "        self.url = URL\n",
    "        self.driver = self.create_driver()\n",
    "\n",
    "    def _create_options(self):\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(ARG_WINDOW_SIZE)\n",
    "        prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "        self.chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        return self.chrome_options\n",
    "\n",
    "    def create_driver(self):\n",
    "        self._create_options()\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(URL)\n",
    "        return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search4Articles(Scraper):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user = os.environ.get(\"USER\")\n",
    "        self.pw = os.environ.get(\"PASS\")\n",
    "        \n",
    "        self.db_name = 'articlesWSJ.db'\n",
    "        \n",
    "        self.link_index = 7\n",
    "\n",
    "    def signin_fx(self):\n",
    "        time.sleep(10) #Time to click the cookies        \n",
    "        #####################\n",
    "        sign_in_link = self.driver.find_element(By.LINK_TEXT, \"Sign In\")\n",
    "        sign_in_link.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #####################\n",
    "        username_0 = WebDriverWait(self.driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"username\"))\n",
    "        )\n",
    "        username_0.send_keys(self.user)\n",
    "        time.sleep(2)\n",
    "    \n",
    "        submit_button_0 = self.driver.find_element(By.XPATH, \".//button[@type='button'][@class='solid-button continue-submit new-design']\")\n",
    "        submit_button_0.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        \"\"\"\n",
    "        future warning, make a conditional statement in case this is empty.\n",
    "        \n",
    "        username = WebDriverWait(self.driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"password-login-username\"))\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        password = WebDriverWait(self.driver, 10).until(EC.visibility_of_element_located((By.ID, 'password-login-password')))\n",
    "        password.send_keys(self.pw)\n",
    "        time.sleep(3)\n",
    "\n",
    "        submit_button = self.driver.find_element(By.XPATH, \".//button[@type='submit'][@class='solid-button new-design basic-login-submit']\")\n",
    "        submit_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    def get_webpages_links(self, n_web):\n",
    "        conn = sqlite3.connect(self.db_name)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT * FROM articles_index WHERE scanned_status = 0\") #get list of not scanned\n",
    "        rows = cursor.fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        if rows and len(rows) >= n_web:\n",
    "            links = np.array([[row[0], row[self.link_index]] for row in rows])\n",
    "            pp = np.random.choice(len(rows), n_web)\n",
    "            random_links = links[pp]\n",
    "            return random_links\n",
    "\n",
    "        else:\n",
    "            print(\"No rows found where scanned_status is 0.\")\n",
    "\n",
    "    def insert_elements(self, elements):\n",
    "        \n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_name)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"INSERT INTO article ('image_src', 'scanned_time', 'title', 'sub_title', 'corpus', 'index_id') VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "                  (elements['image_src'], elements['scanned_time'], elements['title'], elements['sub_title'], elements['corpus'], elements['index_id']))\n",
    "            conn.commit()\n",
    "            print(\"Registered\")\n",
    "\n",
    "            row_id = elements['index_id']\n",
    "            new_update_status = 1\n",
    "        \n",
    "            cursor.execute(\"UPDATE articles_index SET scanned_status = ? WHERE id = ?\", (new_update_status, row_id))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print(\"Updated\")\n",
    "            \n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    def get_corpus(self):\n",
    "        try:\n",
    "            h1_element = self.driver.find_element(By.CSS_SELECTOR, \"h1.css-1lvqw7f-StyledHeadline.e1ipbpvp0\")\n",
    "            h1_text = h1_element.text\n",
    "        except NoSuchElementException:\n",
    "            h1_text = 'not found'\n",
    "\n",
    "        try:\n",
    "            h2_element = self.driver.find_element(By.CSS_SELECTOR, \"h2.css-jiugt2-Dek-Dek.e1jnru6p0\")\n",
    "            h2_text = h2_element.text\n",
    "        except NoSuchElementException:\n",
    "            h2_text = 'not found'\n",
    "\n",
    "        try:\n",
    "            section_element = self.driver.find_element(By.CSS_SELECTOR, \"section.ef4qpkp0.css-y2scx8-Container.e1of74uw18\")\n",
    "            section_content = section_element.text\n",
    "        except NoSuchElementException:\n",
    "            section_content = 'not found'\n",
    "\n",
    "        image_links = []\n",
    "\n",
    "        # This block assumes that 'section_element' was successfully found; otherwise, skip it\n",
    "        if section_content != 'not found':\n",
    "            try:\n",
    "                img_elements = section_element.find_elements(By.TAG_NAME, \"img\")\n",
    "                for img_element in img_elements:\n",
    "                    img_src = img_element.get_attribute('src')\n",
    "                    if img_src:  # Check if 'src' attribute is not empty\n",
    "                        image_links.append(img_src)\n",
    "            except NoSuchElementException:\n",
    "                image_links = 'not found'\n",
    "                \n",
    "    def navigation(self, n_web):\n",
    "        list_webs = self.get_webpages_links(n_web)\n",
    "        for web in list_webs:\n",
    "            print(f'index {web[0]} web {web[1]}')\n",
    "            self.driver.get(web[1])\n",
    "            h1_text, h2_text, section_content, image_links = self.get_corpus()\n",
    "            \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "            dict_elements = {\n",
    "                'image_src': str(image_links),\n",
    "                'scanned_time': current_time,\n",
    "                'title': h1_text,\n",
    "                'sub_title': h2_text,\n",
    "                'corpus' : str(section_content),\n",
    "                'index_id': web[0],\n",
    "            }\n",
    "            self.insert_elements(dict_elements)\n",
    "            \n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    n_web = 10 #Number of webpages to scrap\n",
    "    sa =  Search4Articles() #Initiate\n",
    "    sa.signin_fx() #Function to signin\n",
    "    sa.navigation(n_web) #Get the webpages to scrap and call the function to scrap.\n",
    "    print(\"End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
